{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cef3a5f8",
   "metadata": {},
   "source": [
    "# 1. Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "23c0194f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "from basic_functions import data_load, evaluate_model, save_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "472e8fdb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data loaded!\n",
      "Data loaded!\n",
      "Data loaded!\n",
      "Data loaded!\n"
     ]
    }
   ],
   "source": [
    "X_train = data_load(\"data/X_train.csv\")\n",
    "y_train = data_load(\"data/y_train_clustered.csv\")\n",
    "X_test = data_load(\"data/X_test.csv\")\n",
    "y_test = data_load(\"data/y_test_clustered.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9fda06ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train[\"job_major\"] = X_train[\"job\"].astype(str).str[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "89784279",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_evaluation = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92860f33",
   "metadata": {},
   "source": [
    "# 2. Random Guesser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bf788283",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random_Guess:\n",
      "Accuracy: 0.13199910051720262\n",
      "Macro-F1: 0.12105423894465372\n",
      "Weighted-F1: 0.14265139338547475\n",
      "Log-Loss: 1.945910149055314\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.10      0.13      0.11       498\n",
      "           1       0.27      0.14      0.18      1243\n",
      "           2       0.14      0.13      0.14       641\n",
      "           3       0.20      0.14      0.16       940\n",
      "           4       0.09      0.12      0.10       458\n",
      "           5       0.11      0.14      0.12       498\n",
      "           6       0.02      0.07      0.03       169\n",
      "\n",
      "    accuracy                           0.13      4447\n",
      "   macro avg       0.13      0.12      0.12      4447\n",
      "weighted avg       0.17      0.13      0.14      4447\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.metrics import accuracy_score, f1_score, classification_report\n",
    "\n",
    "# --- Random Guess (uniform) ---\n",
    "random_clf = DummyClassifier(strategy=\"uniform\", random_state=42)\n",
    "random_clf.fit(X_train, y_train)\n",
    "y_pred_random = random_clf.predict(X_test)\n",
    "y_probs_random = random_clf.predict_proba(X_test)\n",
    "random_df = evaluate_model(y_pred=y_pred_random, y_test=y_test, model_name=\"Random_Guess\", y_proba=y_probs_random)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ec9271b",
   "metadata": {},
   "source": [
    "# 3. Majority Guesser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "709b2343",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Majority_Guess:\n",
      "Accuracy: 0.2795142792894086\n",
      "Macro-F1: 0.06241526487572181\n",
      "Weighted-F1: 0.12212170444876445\n",
      "Log-Loss: 25.968937589100822\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00       498\n",
      "           1       0.28      1.00      0.44      1243\n",
      "           2       0.00      0.00      0.00       641\n",
      "           3       0.00      0.00      0.00       940\n",
      "           4       0.00      0.00      0.00       458\n",
      "           5       0.00      0.00      0.00       498\n",
      "           6       0.00      0.00      0.00       169\n",
      "\n",
      "    accuracy                           0.28      4447\n",
      "   macro avg       0.04      0.14      0.06      4447\n",
      "weighted avg       0.08      0.28      0.12      4447\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.metrics import accuracy_score, f1_score, classification_report\n",
    "\n",
    "# --- Majority Class ---\n",
    "majority_clf = DummyClassifier(strategy=\"most_frequent\")\n",
    "majority_clf.fit(X_train, y_train)\n",
    "y_pred_majority = majority_clf.predict(X_test)\n",
    "y_probs_majority = majority_clf.predict_proba(X_test)\n",
    "majority_df= evaluate_model(y_pred=y_pred_majority, y_test=y_test, model_name=\"Majority_Guess\", y_proba=y_probs_majority)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb37176f",
   "metadata": {},
   "source": [
    "# 4. Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4da61ccf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            Model  Accuracy  Macro-F1  Weighted-F1   Log-Loss\n",
      "0    Random_Guess  0.131999  0.121054     0.142651   1.945910\n",
      "1  Majority_Guess  0.279514  0.062415     0.122122  25.968938\n"
     ]
    }
   ],
   "source": [
    "df_eval = pd.concat([\n",
    "    random_df,\n",
    "    majority_df\n",
    "], ignore_index=True)\n",
    "\n",
    "print(df_eval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "03a02d69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data saved!\n"
     ]
    }
   ],
   "source": [
    "save_df(df_eval, \"data/model_comparison.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
